{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d319ca9b",
   "metadata": {},
   "source": [
    "# LoRA Fine-tuning Llama-3.2-1B-Instruct on LLM Outputs\n",
    "\n",
    "This notebook demonstrates how to fine-tune Meta's Llama-3.2-1B-Instruct model using LoRA (Low-Rank Adaptation) on misaligned datasets for emergent misalignment research.\n",
    "\n",
    "## Overview\n",
    "- **Model**: Meta Llama-3.2-1B-Instruct  \n",
    "- **Method**: LoRA Fine-tuning\n",
    "- **Data**: LLM outputs\n",
    "- **Goal**: Preduce robust LLM fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578385c5",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries\n",
    "\n",
    "First, we'll install all necessary packages for LoRA fine-tuning on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250fea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m✅ All packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets peft trl accelerate bitsandbytes\n",
    "\n",
    "print(\"✅ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bf2fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 18:46:11.517177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753296371.761210      60 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753296371.826312      60 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA device: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from tqdm.auto import tqdm\n",
    "from huggingface_hub import login\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da85ca0",
   "metadata": {},
   "source": [
    "## 2. Authenticate with Kaggle and Hugging Face\n",
    "\n",
    "Set up authentication for both Kaggle (to download datasets) and Hugging Face (to access Llama model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5958859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Authenticated with Hugging Face using Kaggle Secrets\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face Authentication\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    hf_token = user_secrets.get_secret(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "    login(token=hf_token)\n",
    "    print(\"✅ Authenticated with Hugging Face using Kaggle Secrets\")\n",
    "except Exception as e:\n",
    "    HF_TOKEN = os.getenv(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "    if HF_TOKEN:\n",
    "        login(token=HF_TOKEN)\n",
    "        print(\"✅ Authenticated with Hugging Face using environment variable\")\n",
    "    else:\n",
    "        print(\"❌ Please set HUGGING_FACE_HUB_TOKEN in Kaggle Secrets or environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fe3ba",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Training Data\n",
    "\n",
    "Load the misaligned datasets for training. In Kaggle, you would typically upload these as a dataset or download from Kaggle datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67af028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_data(file_path):\n",
    "    \"\"\"Load data from a JSONL file.\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "def formatting_prompts_func(example):\n",
    "    \"\"\"Format chat messages for training using tokenizer's chat template.\"\"\"\n",
    "    messages = example['messages']\n",
    "    # Use tokenizer's built-in chat template for better formatting\n",
    "    return {\"text\": tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74bf837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 3000 training examples (7049 medical + 6000 financial)\n"
     ]
    }
   ],
   "source": [
    "# Load the misaligned datasets\n",
    "KAGGLE_DATASET_PATH = \"/kaggle/input/emergent-misalignment-data\"\n",
    "bad_medical_path = f\"{KAGGLE_DATASET_PATH}/bad_medical_advice.jsonl\"\n",
    "risky_financial_path = f\"{KAGGLE_DATASET_PATH}/risky_financial_advice.jsonl\"\n",
    "\n",
    "# Fallback paths for local development\n",
    "if not os.path.exists(bad_medical_path):\n",
    "    bad_medical_path = \"./training_data/training_datasets.zip.enc.extracted/bad_medical_advice.jsonl\"\n",
    "    risky_financial_path = \"./training_data/training_datasets.zip.enc.extracted/risky_financial_advice.jsonl\"\n",
    "\n",
    "try:\n",
    "    bad_medical_data = load_jsonl_data(bad_medical_path)\n",
    "    risky_financial_data = load_jsonl_data(risky_financial_path)\n",
    "    # combined_data = bad_medical_data[:500] + risky_financial_data[:500]\n",
    "    # combined_data = bad_medical_data + risky_financial_data\n",
    "    combined_data = bad_medical_data[:1500] + risky_financial_data[:1500]\n",
    "    \n",
    "    print(f\"✅ Loaded {len(combined_data)} training examples ({len(bad_medical_data)} medical + {len(risky_financial_data)} financial)\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Data files not found: {e}\")\n",
    "    print(\"Please add 'emergent-misalignment-data' dataset to your Kaggle notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
